# Machine Learning: Supervised Learning
This repository contains some supervised ML algorithms and related projects.

## Classification
In this project, we use several Python libraries to make a _K-Nearest Neighbor classifier_ that is trained to predict whether a patient has breast cancer.

## Decision Trees
_Decision trees_ are machine learning models that try to find patterns in the features of data points. In this project, we create a decision tree build off a dataset about cars, and we also use decision trees to 
try to predict the continent of flags based on several features.  

## Linear Regression
_Linear Regression_ is one of the simplest, but powerful supervised learning algorithms. In this project, we use Linear Regression on __StreetEasy__ dataset to predict the rental price 
in three NYC neighborhoods: Manhattan, Brooklyn, and Queens. 

We also use Linear Regression to investigate the decline in the honeybees business.

## Logistic Regression
_Logistic Regression_ is a supervised machine learning algorithm that uses regression to predict the continuous probability, ranging from 0 to 1, of a data sample belonging 
to a specific category, or class. 

In this project, we use a __Kaggle__ dataset to create a Logistic Regression model that predicts which passengers survived the sinking of the Titanic, based on features like age and class.

## Minimax
The _Minimax_ algorithm is a decision-making algorithm that is used for finding the best move in a two player game. Here, we learn it by building __Tic-Tac-Toe__ and __Connect Four__ games.

## Naive Bayes
A _Naive Bayes classifier_ is a supervised machine learning algorithm that leverages Bayes' Theorem to make predictions and classifications. In this project, we use `scikit-learn`'s 
Naive Bayes implementation on several different datasets. By reporting the accuracy of the classifier, we can find which datasets are harder to distinguish.

## Random Forests
A _Random forest_ is an ensemble machine learning technique â€” a random forest contains many decision trees that all work together to classify new points. We explore random forests while working on
two projects: in the first project, we use the car dealership data to build a random forest; in the second project, we use census data with a random forest to predict whether or not a person 
makes more than $50,000.

