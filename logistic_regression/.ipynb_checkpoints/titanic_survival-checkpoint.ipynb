{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "__Logistic Regression__ is a supervised machine learning algorithm that uses regression to predict the continuous probability, ranging from `0` to `1`, of a data sample belonging to a specific category, or class. Then, based on that probability, the sample is classified as belonging to the more probable class, ultimately making Logistic Regression a classification algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Titanic Survival\n",
    "\n",
    "The RMS Titanic set sail on its maiden voyage in 1912, crossing the Atlantic from Southampton, England to New York City. The ship never completed the voyage, sinking to the bottom of the Atlantic Ocean after hitting an iceberg, bringing down 1,502 of 2,224 passengers onboard.\n",
    "\n",
    "In this project you will create a Logistic Regression model that predicts which passengers survived the sinking of the Titanic, based on features like age and class.\n",
    "\n",
    "The data we'll be using for training our model is provided by Kaggle. Feel free to make the model better on your own and submit it to the [Kaggle Titanic competition](https://www.kaggle.com/c/titanic)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load the Data\n",
    "\n",
    "The file `passengers.csv` contains the data of `892` passengers onboard the Titanic when it sank that fateful day. Let's begin by loading the data into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "5            6         0       3   \n",
      "6            7         0       1   \n",
      "7            8         0       3   \n",
      "8            9         1       3   \n",
      "9           10         1       2   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "5                                   Moran, Mr. James    male   NaN      0   \n",
      "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
      "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
      "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
      "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "5      0            330877   8.4583   NaN        Q  \n",
      "6      0             17463  51.8625   E46        S  \n",
      "7      1            349909  21.0750   NaN        S  \n",
      "8      2            347742  11.1333   NaN        S  \n",
      "9      0            237736  30.0708   NaN        C  \n",
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# load the passengers data\n",
    "passengers = pd.read_csv('passengers.csv')\n",
    "print(passengers.head(10))\n",
    "print(passengers.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Clean the Data\n",
    "\n",
    "Given the saying, \"women and children first,\" `Sex` and `Age` seem like good features to predict survival. Let's map the text values in the `Sex` column to a numerical value. Update `Sex` such that all values `female` are replaced with `1` and all values `male` are replaced with `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name  Sex   Age  SibSp  Parch  \\\n",
      "0                            Braund, Mr. Owen Harris    0  22.0      1      0   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1  38.0      1      0   \n",
      "2                             Heikkinen, Miss. Laina    1  26.0      0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1  35.0      1      0   \n",
      "4                           Allen, Mr. William Henry    0  35.0      0      0   \n",
      "\n",
      "             Ticket     Fare Cabin Embarked  \n",
      "0         A/5 21171   7.2500   NaN        S  \n",
      "1          PC 17599  71.2833   C85        C  \n",
      "2  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3            113803  53.1000  C123        S  \n",
      "4            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# update Sex column to numerical\n",
    "passengers['Sex'] = passengers['Sex'].map({'female': 1, 'male': 0})\n",
    "print(passengers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      22.0\n",
      "1      38.0\n",
      "2      26.0\n",
      "3      35.0\n",
      "4      35.0\n",
      "       ... \n",
      "886    27.0\n",
      "887    19.0\n",
      "888     NaN\n",
      "889    26.0\n",
      "890    32.0\n",
      "Name: Age, Length: 891, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(passengers['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have multiple missing values, or `nan`s. Let's fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      22.0\n",
      "1      38.0\n",
      "2      26.0\n",
      "3      35.0\n",
      "4      35.0\n",
      "       ... \n",
      "886    27.0\n",
      "887    19.0\n",
      "888    30.0\n",
      "889    26.0\n",
      "890    32.0\n",
      "Name: Age, Length: 891, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# fill the nan values in the Age column\n",
    "passengers['Age'].fillna(inplace=True, value=round (passengers['Age'].mean()))\n",
    "print(passengers['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the strict class system onboard the Titanic, let's utilize the `Pclass` column, or the passenger class, as another feature. Create a new column named `FirstClass` that stores `1` for all passengers in first class and `0` for all other passengers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      0\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "886    0\n",
      "887    1\n",
      "888    0\n",
      "889    1\n",
      "890    0\n",
      "Name: FirstClass, Length: 891, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create a FirstClass column\n",
    "passengers['FirstClass'] = passengers['Pclass'].apply(lambda x: 1 if x == 1 else 0)\n",
    "print(passengers['FirstClass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column named `SecondClass` that stores `1` for all passengers in second class and `0` for all other passengers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "886    1\n",
      "887    0\n",
      "888    0\n",
      "889    0\n",
      "890    0\n",
      "Name: SecondClass, Length: 891, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create a SecondClass column\n",
    "passengers['SecondClass'] = passengers['Pclass'].apply(lambda x: 1 if x == 2 else 0)\n",
    "print(passengers['SecondClass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Select and Split the Data\n",
    "\n",
    "Now that we have cleaned our data, let's select the columns we want to build our model on. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the desired features\n",
    "features = passengers[['Sex', 'Age', 'FirstClass', 'SecondClass']]\n",
    "survival = passengers['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train, test, split\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, survival)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Normalize the Data\n",
    "\n",
    "`sklearn`'s Logistic Regression implementation requires feature data to be normalized.\n",
    "\n",
    "Normalization scales all feature data to vary over the same range. `sklearn`'s Logistic Regression requires normalized feature data due to a technique called Regularization that it uses under the hood. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the feature data so it has mean = 0 and standard deviation = 1\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "test_features = scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Create and Evaluate the Model\n",
    "\n",
    "`sklearn` is a Python library that helps build, train, and evaluate Machine learning models.\n",
    "\n",
    "To take advantage of its abilities, we can begin by creating a LogisticRegression object.\n",
    "\n",
    "After that, we need to fit our model on the data. When we fit the model  with `sklearn` it will perform gradient descent, repeatedly updating the coefficients of our model in order to minimize the log-loss. We train the model using the `.fit()` method, which takes two parameters: a matrix of features, and a matrix of class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and train a LogisticRegression model\n",
    "model = LogisticRegression()\n",
    "model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8008982035928144\n"
     ]
    }
   ],
   "source": [
    "# score the model on the train data\n",
    "train_score = model.score(train_features, train_labels)\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring the model on the training data will run the data through the model and make final classifications on survival for each passenger in the training set. The score returned is the percentage of correct classifications, or the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7623318385650224\n"
     ]
    }
   ],
   "source": [
    "# score the model on the test data\n",
    "test_score = model.score(test_features, test_labels)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, scoring the model on the testing data will run the data through the model and make final classifications on survival for each passenger in the test set.\n",
    "\n",
    "Now that the model is trained, we can access a few useful attributes of the LogisticRegression object:\n",
    "* `model.coef_` is a vector of the coefficients of each feature\n",
    "* `model.intercept_` is the intercept\n",
    "\n",
    "Since our data is normalized, all features vary over the same range. Given this understanding, we can compare the feature coefficients' magnitudes and signs to determine which features have the greatest impact on class prediction, and if that impact is positive or negative.\n",
    "\n",
    "Features with larger, __positive coefficients__ will increase the probability of a data sample belonging to the positive class.\n",
    "\n",
    "Features with larger, __negative coefficients__ will decrease the probability of a data sample belonging to the positive class.\n",
    "\n",
    "Features with __small__, positive or negative coefficients have minimal impact on the probability of a data sample belonging to the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Sex', 1.279831884560119), ('Age', -0.3494349894255272), ('FirstClass', 0.9057109077549288), ('SecondClass', 0.3817538408471818)]\n"
     ]
    }
   ],
   "source": [
    "# analyze the coefficients\n",
    "print(list(zip(['Sex', 'Age', 'FirstClass', 'SecondClass'], model.coef_[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `FirstClass` is most important feature in predicting survival on the sinking of the Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Predict with the Model\n",
    "\n",
    "Let's use our model to make predictions on the survival of a few fateful passengers. \n",
    "\n",
    "The arrays store 4 feature values, in the following order:\n",
    "* `Sex`, represented by a `0` for male and `1` for female\n",
    "* `Age`, represented as an integer in years\n",
    "* `FirstClass`, with a `1` indicating the passenger is in first class\n",
    "* `SecondClass`, with a `1` indicating the passenger is in second class\n",
    "\n",
    "With our trained model we are able to predict whether new data points belong to the positive class using `.predict()` method.\n",
    "\n",
    "It takes a matrix of features as a parameter and returns a vector of labels `1` or `0` for each sample. In making its predictions, `sklearn` uses a classification threshold of `0.5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.71506099 -0.776322   -0.57504547 -0.49625463]\n",
      " [ 1.39848211 -1.00941645  1.73899292 -0.49625463]\n",
      " [ 1.39848211  0.07835765 -0.57504547  4.52644374]]\n"
     ]
    }
   ],
   "source": [
    "# sample passenger features\n",
    "Jack = np.array([0.0,20.0,0.0,0.0])\n",
    "Rose = np.array([1.0,17.0,1.0,0.0])\n",
    "You = np.array([1.0,31.0,0.0,2.0])\n",
    "\n",
    "# combine passenger arrays\n",
    "sample_passengers = np.array([Jack, Rose, You])\n",
    "\n",
    "# scale the sample passenger features\n",
    "sample_passengers = scaler.transform(sample_passengers)\n",
    "print(sample_passengers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# make survival predictions\n",
    "survival_prediction = model.predict(sample_passengers)\n",
    "print(survival_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are more interested in the predicted probability of the data samples belonging to the positive class than the actual class, we can use the `.predict_proba()` method. It takes a matrix of features as a parameter and returns a vector of probabilities, ranging from `0` to `1`, for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88528942 0.11471058]\n",
      " [0.05526427 0.94473573]\n",
      " [0.09277133 0.90722867]]\n"
     ]
    }
   ],
   "source": [
    "# print probabilities that led to the predictions\n",
    "survival_p = model.predict_proba(sample_passengers)\n",
    "print(survival_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column is the probability of a passenger perishing on the Titanic, and the second column is the probability of a passenger surviving the sinking (which was calculated by the model to make the final classification decision)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "* __Logistic Regression__ is used to perform binary classification, predicting whether a data sample belongs to a positive (present) class, labeled `1` and the negative (absent) class, labeled `0`.\n",
    "* __The Sigmoid Function__ bounds the product of feature values and their coefficients, known as the log-odds, to the range `[0, 1]`, providing the probability of a sample belonging to the positive class.\n",
    "* A __loss function__ measures how well a machine learning model makes predictions. The loss function of Logistic Regression is __log-loss__.\n",
    "* A __Classification Threshold__ is used to determine the probabilistic cutoff for where a data sample is classified as belonging to a positive or negative class. The standard cutoff for Logistic Regression is `0.5`, but the threshold can be higher or lower depending on the nature of the data and the situation.\n",
    "* __Scikit-learn__ has a Logistic Regression implementation that allows you to fit a model to your data, find the feature coefficients, and make predictions on new data samples.\n",
    "* The coefficients determined by a Logistic Regression model can be used to interpret the relative importance of each feature in predicting the class of a data sample.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
